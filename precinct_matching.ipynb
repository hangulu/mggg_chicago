{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precinct Matching\n",
    "\n",
    "This notebook executes matches precincts in different cities by their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import collections\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the races and the demographic columns\n",
    "races = ['white','black','hispanic','asian','middle eastern','undetermined']\n",
    "demo_cols = ['NH_WHITE', 'NH_BLACK', 'NH_AMIN',\t'NH_ASIAN',\t'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'HISP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'match_data/chicago_prec_demo.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9b08f8fd49e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read in Chicago demographic data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_chic_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'match_data/chicago_prec_demo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdemo_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_chic_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_chic_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_chic_demo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_chic_demo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_chic_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'match_data/chicago_prec_demo.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Read in Chicago demographic data\n",
    "df_chic_demo = pd.read_csv('match_data/chicago_prec_demo.csv',index_col=0).dropna()[demo_cols]\n",
    "df_chic_demo.reindex(sorted(df_chic_demo.columns), axis=1)\n",
    "df_chic_demo = df_chic_demo[(df_chic_demo.T !=0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Cambridge demographic data\n",
    "df_camb_demo = pd.read_csv('match_data/camb_prec_demo.csv',index_col=0).dropna()[demo_cols]\n",
    "df_camb_demo.reindex(sorted(df_camb_demo.columns), axis=1)\n",
    "df_camb_demo = df_camb_demo[(df_camb_demo.T !=0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Minneapolis demographic data\n",
    "df_minn_demo = pd.read_csv('match_data/minn_prec_demo.csv',index_col=0).dropna()[demo_cols]\n",
    "df_minn_demo.reindex(sorted(df_minn_demo.columns), axis=1)\n",
    "df_minn_demo = df_minn_demo[(df_minn_demo.T !=0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary\n",
    "# keys: Chicago precincts\n",
    "# values: (P, s)\n",
    "# P is a precinct in another city\n",
    "# s is the cosine similarity in demographic space\n",
    "chic_dict = {}\n",
    "\n",
    "for row in df_chic_demo.itertuples():\n",
    "    distpairs1 = []\n",
    "    distpairs2 = []\n",
    "\n",
    "    for r2 in df_camb_demo.itertuples():\n",
    "        distpairs1.append((list(r2)[0],  1 - spatial.distance.cosine(list(row)[1:], list(r2)[1:])))\n",
    "\n",
    "    for r2 in df_minn_demo.itertuples():\n",
    "        distpairs2.append((list(r2)[0],  1 - spatial.distance.cosine(list(row)[1:], list(r2)[1:])))\n",
    "    \n",
    "    # We're grabbing the 5 most similar in cambridge and the 15 most similar in mpls\n",
    "    distpairs1.sort(key=lambda x: x[1], reverse=True)\n",
    "    distpairs2.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    chic_dict[list(row)[0]] = distpairs1[:5] + distpairs2[:15]\n",
    "\n",
    "# Choose the columns to be kept\n",
    "camb_keep_cols = ['ID','1st Choice','2nd Choice','3rd Choice','4th Choice','5th Choice']\n",
    "camb_prec_votes = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Cambridge Voting Data\n",
    "df_camb_vote = pd.read_excel('match_data/Cambridge City Council CVR 2017.xlsx')\n",
    "\n",
    "# Format the data\n",
    "df_camb_vote['ID'] = df_camb_vote['ID'].apply(lambda x: str(x)[2:4] + '-' + str(x)[4:6])\n",
    "df_camb_vote['ID'] = df_camb_vote['ID'].apply(lambda x: str(x).replace(\"-0\",\"-\"))\n",
    "df_camb_vote['ID'] = df_camb_vote['ID'].apply(lambda x: str(x)[1:] if str(x)[0] == '0' else str(x))\n",
    "df_camb_vote = df_camb_vote.drop(columns=[c for c in list(df_camb_vote) if c not in camb_keep_cols ])\n",
    "\n",
    "# Read in the demographic IDs\n",
    "df_camb_id = pd.read_csv('match_data/camb_demo_id_2017.csv',delimiter='\\t',header=None)\n",
    "df_camb_id = dict(zip(df_camb_id[0],df_camb_id[1]))\n",
    "\n",
    "# Reformat the Cambridge voting data with demographics\n",
    "for c in camb_keep_cols[1:]:\n",
    "    df_camb_vote[c] = df_camb_vote[c].apply(lambda e: df_camb_id[e].capitalize() if e in df_camb_id.keys() else np.nan)\n",
    "\n",
    "df_camb_vote = df_camb_vote[pd.notnull(df_camb_vote['1st Choice'])]\n",
    "\n",
    "# Record the precinct votes\n",
    "for row in df_camb_vote.itertuples():\n",
    "    camb_prec_votes[list(row)[1]].append(tuple([ str(s).lower().replace(\"middle eastern\",\"asian\") for s in list(row)[2:5]] + []))\n",
    "\n",
    "for k,v in camb_prec_votes.items():\n",
    "    camb_prec_votes[k] = collections.Counter(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Minneapolis Voting Data\n",
    "minn_prec_votes = collections.defaultdict(list)\n",
    "df_minn_vote = pd.read_csv('match_data/2017-mayor-cvr.csv').drop(columns = ['1st Choice','2nd Choice','3rd Choice','Count'])\n",
    "\n",
    "df_minn_vote = df_minn_vote[pd.notnull(df_minn_vote['1st Choice_Race'])]\n",
    "\n",
    "# Record the precinct votes\n",
    "for row in df_minn_vote.itertuples():\n",
    "    k = list(row)[1].replace(\"MINNEAPOLIS \",'').replace(\"W-\",'W').replace(\"P-\",\"P\").replace(' ','-').replace(\"P0\",'P')\n",
    "    minn_prec_votes[k].append(tuple([str(s).lower().replace(\"middle eastern\",\"asian\") for s in list(row)[2:]]))\n",
    "\n",
    "for k,v in minn_prec_votes.items():\n",
    "    minn_prec_votes[k] = collections.Counter(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty votes\n",
    "chic_impute = collections.defaultdict(dict)\n",
    "\n",
    "for k,v in camb_prec_votes.items():\n",
    "    if v == []:\n",
    "        print(\"remove\")\n",
    "        camb_prec_votes.pop(k,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each precinct in chicago\n",
    "# For each match precint P in that dictionary\n",
    "# Use the weight s on P times the percentage of\n",
    "# people in P voting each preference schedule\n",
    "# and sum, then normalize so that the total\n",
    "# votes is equal to VAP\n",
    "for prec in chic_dict.keys():\n",
    "    for match in chic_dict[prec]:\n",
    "        if match[0][0] == 'W':\n",
    "            for k,v in minn_prec_votes[match[0]].items():\n",
    "                if k in chic_impute[prec].keys():\n",
    "                    chic_impute[prec][k] += v * match[1] ** 1\n",
    "                else:\n",
    "                    chic_impute[prec][k] = v * match[1] ** 1\n",
    "        else:\n",
    "            if match[0] == \"3-2A\":\n",
    "                m = \"3-2\"\n",
    "            else: \n",
    "                m = match[0]\n",
    "\n",
    "            for k,v in camb_prec_votes[m].items():\n",
    "                if k in chic_impute[prec].keys():\n",
    "                    chic_impute[prec][k] += v * match[1] ** 1\n",
    "                else:\n",
    "                    chic_impute[prec][k] = v * match[1] ** 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in precinct demographics\n",
    "df_chic_demo = pd.read_csv('match_data/chicago_prec_demo.csv',index_col=0).dropna()\n",
    "for k,v in chic_impute.items():\n",
    "    tot = sum(list(v.values()))\n",
    "    for k2 in v.keys():\n",
    "        v[k2] = v[k2]/tot * df_chic_demo.at[k,'VAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Results:\n",
    "chic_impute\n",
    "chic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise data\n",
    "totvots = collections.defaultdict(float)\n",
    "\n",
    "for v in chic_impute.values():\n",
    "    for k2,v2 in v.items():\n",
    "        totvots[k2] += v2\n",
    "\n",
    "print(len(totvots.keys()))\n",
    "\n",
    "races = ['white','black','hispanic','asian','undetermined']\n",
    "for r in races:\n",
    "    sums = [0,0,0]\n",
    "    for k,v in totvots.items():\n",
    "        for i in range(1):\n",
    "            if k[i] == r:\n",
    "                sums[i] += v\n",
    "    for i in range(1):\n",
    "        print(\"{} Choice {}: {}\".format(i+1,r,sums[i]))\n",
    "for r in races:\n",
    "    tot = 0\n",
    "    for k,v in totvots.items():\n",
    "        if r in k:\n",
    "            tot+=v\n",
    "\n",
    "    print(\"{} in top 3: {}\".format(r,tot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
